diff --git a/tensorflow/core/kernels/gpu_utils.h b/tensorflow/core/kernels/gpu_utils.h
index 1234567..abcdefg 100644
--- a/tensorflow/core/kernels/gpu_utils.h
+++ b/tensorflow/core/kernels/gpu_utils.h
@@ -156,8 +156,8 @@ class GpuLaunchKernel {
 template <typename T>
 struct GpuLaunchConfig {
   // Template instantiation fix for LLVM 22
-  template<typename U = T>
-  static constexpr bool is_supported_type() {
+  template<typename U>
+  static constexpr bool is_supported_type_impl() {
     return std::is_same_v<U, float> || 
            std::is_same_v<U, double> ||
            std::is_same_v<U, int32> ||
@@ -165,6 +165,10 @@ struct GpuLaunchConfig {
            std::is_same_v<U, Eigen::half>;
   }
   
+  static constexpr bool is_supported_type() {
+    return is_supported_type_impl<T>();
+  }
+  
   int thread_per_block;
   int block_count;
   size_t shared_memory_size;
@@ -189,7 +193,7 @@ struct GpuLaunchConfig {
 template <typename T>
 GpuLaunchConfig<T> GetGpuLaunchConfig(int work_element_count,
                                       const GPUDevice& d) {
-  static_assert(GpuLaunchConfig<T>::is_supported_type(), 
+  static_assert(GpuLaunchConfig<T>::is_supported_type(),
                 "Unsupported type for GPU launch configuration");
   
   GpuLaunchConfig<T> config;
diff --git a/tensorflow/core/kernels/cuda_solvers.h b/tensorflow/core/kernels/cuda_solvers.h
index 2345678..bcdefgh 100644
--- a/tensorflow/core/kernels/cuda_solvers.h
+++ b/tensorflow/core/kernels/cuda_solvers.h
@@ -78,11 +78,15 @@ class CudaSolver {
   // Template specialization fix for CUDA 12.8 and LLVM 22
   template <typename Scalar>
   struct SolverTraits {
-    static constexpr bool is_supported = 
+    template<typename U>
+    static constexpr bool is_supported_impl() {
+      return std::is_same_v<U, float> || std::is_same_v<U, double> ||
+             std::is_same_v<U, std::complex<float>> || std::is_same_v<U, std::complex<double>>;
+    }
+    
+    static constexpr bool is_supported() {
+      return is_supported_impl<Scalar>();
+    }
-      std::is_same_v<Scalar, float> || std::is_same_v<Scalar, double> ||
-      std::is_same_v<Scalar, std::complex<float>> ||
-      std::is_same_v<Scalar, std::complex<double>>;
   };
   
   template <typename Scalar>
@@ -92,7 +96,7 @@ class CudaSolver {
                            const Tensor& rhs,
                            Tensor* solution,
                            OpKernelContext* context) {
-    static_assert(SolverTraits<Scalar>::is_supported,
+    static_assert(SolverTraits<Scalar>::is_supported(),
                   "Unsupported scalar type for CUDA solver");
     
     // Implementation continues...
diff --git a/third_party/xla/xla/service/gpu/gpu_compiler.cc b/third_party/xla/xla/service/gpu/gpu_compiler.cc
index 3456789..cdefghi 100644
--- a/third_party/xla/xla/service/gpu/gpu_compiler.cc
+++ b/third_party/xla/xla/service/gpu/gpu_compiler.cc
@@ -234,12 +234,16 @@ class GpuCompiler::CompilationState {
   // Template deduction fix for compute capability handling
   template <int major, int minor>
   struct ComputeCapability {
-    static constexpr bool is_sm120 = (major == 12 && minor == 0);
-    static constexpr bool is_supported = major >= 6 || is_sm120;
+    template<int M, int N>
+    static constexpr bool is_sm120_impl() { return M == 12 && N == 0; }
+    
+    template<int M, int N>
+    static constexpr bool is_supported_impl() { return M >= 6 || is_sm120_impl<M, N>(); }
+    
+    static constexpr bool is_sm120() { return is_sm120_impl<major, minor>(); }
+    static constexpr bool is_supported() { return is_supported_impl<major, minor>(); }
   };
   
-  template <int major, int minor>
-  static constexpr bool kIsSupported = ComputeCapability<major, minor>::is_supported;
 };
 
 StatusOr<std::unique_ptr<HloModule>> GpuCompiler::RunHloPasses(
