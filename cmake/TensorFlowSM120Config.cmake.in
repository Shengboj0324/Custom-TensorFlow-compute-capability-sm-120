# TensorFlow SM120 CMake Configuration File
# This file provides configuration for finding and using TensorFlow SM120 libraries

@PACKAGE_INIT@

# Package information
set(TensorFlowSM120_VERSION "@PROJECT_VERSION@")
set(TensorFlowSM120_VERSION_MAJOR "@PROJECT_VERSION_MAJOR@")
set(TensorFlowSM120_VERSION_MINOR "@PROJECT_VERSION_MINOR@")
set(TensorFlowSM120_VERSION_PATCH "@PROJECT_VERSION_PATCH@")

# Installation paths
set_and_check(TensorFlowSM120_INCLUDE_DIR "@PACKAGE_CMAKE_INSTALL_INCLUDEDIR@")
set_and_check(TensorFlowSM120_LIB_DIR "@PACKAGE_CMAKE_INSTALL_LIBDIR@")
set_and_check(TensorFlowSM120_BIN_DIR "@PACKAGE_CMAKE_INSTALL_BINDIR@")

# Find required dependencies
find_package(CUDA 12.4 REQUIRED)
find_package(PkgConfig REQUIRED)

# Check for TensorFlow
find_path(TENSORFLOW_INCLUDE_DIR
    NAMES tensorflow/core/framework/op.h
    PATHS
        /usr/local/include
        /usr/include
        ${CMAKE_INSTALL_PREFIX}/include
    PATH_SUFFIXES tensorflow
)

if(NOT TENSORFLOW_INCLUDE_DIR)
    set(TensorFlowSM120_FOUND FALSE)
    if(TensorFlowSM120_FIND_REQUIRED)
        message(FATAL_ERROR "TensorFlow headers not found. Please install TensorFlow development headers.")
    endif()
    return()
endif()

# Find TensorFlow libraries
find_library(TENSORFLOW_FRAMEWORK_LIB
    NAMES tensorflow_framework
    PATHS
        /usr/local/lib
        /usr/lib
        ${CMAKE_INSTALL_PREFIX}/lib
)

# CUDA libraries
find_library(CUDA_CUDART_LIBRARY cudart ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
find_library(CUDA_CUBLAS_LIBRARY cublas ${CUDA_TOOLKIT_ROOT_DIR}/lib64)
find_library(CUDA_CUDNN_LIBRARY cudnn ${CUDA_TOOLKIT_ROOT_DIR}/lib64)

# Check for cuDNN
find_path(CUDNN_INCLUDE_DIR cudnn.h
    PATHS ${CUDA_TOOLKIT_ROOT_DIR}/include
          /usr/include
          /usr/local/include)

if(NOT CUDNN_INCLUDE_DIR)
    set(TensorFlowSM120_FOUND FALSE)
    if(TensorFlowSM120_FIND_REQUIRED)
        message(FATAL_ERROR "cuDNN headers not found. Please install cuDNN 9.x for CUDA 12.4+")
    endif()
    return()
endif()

# Import targets
include("${CMAKE_CURRENT_LIST_DIR}/TensorFlowSM120Targets.cmake")

# Set up imported targets
if(NOT TARGET TensorFlowSM120::sm120_cuda_kernels)
    add_library(TensorFlowSM120::sm120_cuda_kernels SHARED IMPORTED)
    set_target_properties(TensorFlowSM120::sm120_cuda_kernels PROPERTIES
        IMPORTED_LOCATION "${TensorFlowSM120_LIB_DIR}/libsm120_cuda_kernels.so"
        INTERFACE_INCLUDE_DIRECTORIES "${TensorFlowSM120_INCLUDE_DIR}"
    )
endif()

if(NOT TARGET TensorFlowSM120::sm120_tensorflow_ops)
    add_library(TensorFlowSM120::sm120_tensorflow_ops SHARED IMPORTED)
    set_target_properties(TensorFlowSM120::sm120_tensorflow_ops PROPERTIES
        IMPORTED_LOCATION "${TensorFlowSM120_LIB_DIR}/libsm120_tensorflow_ops.so"
        INTERFACE_INCLUDE_DIRECTORIES "${TensorFlowSM120_INCLUDE_DIR}"
        INTERFACE_LINK_LIBRARIES "TensorFlowSM120::sm120_cuda_kernels"
    )
endif()

# Compiler definitions
set(TensorFlowSM120_DEFINITIONS
    -DGOOGLE_CUDA=1
    -DEIGEN_USE_GPU
    -DTENSORFLOW_USE_ROCM=0
)

# Check for sm_120 GPU support
execute_process(
    COMMAND nvidia-smi --query-gpu=compute_cap --format=csv,noheader,nounits
    OUTPUT_VARIABLE GPU_COMPUTE_CAPS
    ERROR_QUIET
)

string(FIND "${GPU_COMPUTE_CAPS}" "12.0" SM120_FOUND)
if(SM120_FOUND GREATER -1)
    message(STATUS "RTX 50-series GPU with sm_120 support detected")
    list(APPEND TensorFlowSM120_DEFINITIONS -DHAVE_SM120_GPU=1)
    set(TensorFlowSM120_HAS_SM120_GPU TRUE)
else()
    message(STATUS "No RTX 50-series GPU detected. Building with compatibility mode.")
    set(TensorFlowSM120_HAS_SM120_GPU FALSE)
endif()

# Helper function to link TensorFlow SM120
function(target_link_tensorflow_sm120 target)
    target_link_libraries(${target} 
        TensorFlowSM120::sm120_tensorflow_ops
        TensorFlowSM120::sm120_cuda_kernels
    )
    target_compile_definitions(${target} PRIVATE ${TensorFlowSM120_DEFINITIONS})
    target_include_directories(${target} PRIVATE ${TensorFlowSM120_INCLUDE_DIR})
endfunction()

# Set found flag
set(TensorFlowSM120_FOUND TRUE)

# Print configuration summary
if(NOT TensorFlowSM120_FIND_QUIETLY)
    message(STATUS "Found TensorFlow SM120: ${TensorFlowSM120_VERSION}")
    message(STATUS "  Include directory: ${TensorFlowSM120_INCLUDE_DIR}")
    message(STATUS "  Library directory: ${TensorFlowSM120_LIB_DIR}")
    message(STATUS "  SM120 GPU support: ${TensorFlowSM120_HAS_SM120_GPU}")
endif()

check_required_components(TensorFlowSM120)
